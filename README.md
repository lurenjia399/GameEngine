# GameEngine
 directx12和游戏引擎学习

# 1 DX12的一些小概念

##  CommandAllocator  GraphicsCommandList  CommandQueue

1 我们可以向命令列表中添加命令，由cpu将命令列表中的命令提交到命令队列中，gpu就会按照命令队列的顺序依次执行命令，**需要注意的是当命令队列满的时候，cpu就无法在继续提交处于空闲状态，而当命令队列空的时候，gpu就会处于空闲状态**，，

2 下一个概念就是命令分配器，，，他是与命令列表相关联，存储在命令列表中的命令实际上是存储到了命令分配器中。**我们可以创建出多个命令列表关联一个命令分配器，但命令列表不能同时存储命令。**原因是：需要保证命令列表中的数据按照顺序添加到命令分配器中，所以与关联相同命令分配器的命令列表，其中只能有一个命令列表有命令。

3 我们在将命令列表中的命令添加到命令队列中后，就可以执行命令列表.Reset()方法，清空命令列表，就可以复用这个命令列表来存储其他命令。

但是不能将命令分配器清空，因为在将命令提交给命令队列后，命令队列有可能会引用命令分配器中的数据，再加上gpu并不一定会立即执行，所以必须保证gpu在执行完名列队列中的命令后，再将命令分配器清空。

### 为什么要有commandallocator呢？

gpu通过执行命令来实现渲染的操作，而这些命令是通过cpu传过来的。也就是说cpu需要将命令列表中的命令放到显存中 ，而gpu需要从显存中读取命令在执行，这样就对显存有了一读一取的操作，，，在多线程的情况下就会有同步的问题，所以就有了commandallocator来管理显存这块存放命令的区域。这就好比我在饭店点菜，服务员将我点的菜记录到纸上，点完之后，服务员将菜单递交给后厨，后厨根据每道菜依次做，这里的纸就好比是commandallocator。

## D3dDevice

驱动可做的事情很多：

可以帮助我们来创建一些东西：CreateCommandList，CreateCommandQueue，CreateCommandAllocator，CreateFence，CreateDepthStencilView

## 围栏Fence（cpu线程和gpu线程间的同步）

为了充分利用多线程渲染的高性能，draw call 变成异步的，executeCommandlists也变成异步的了（cpu在将这些命令放到命令队列中后，就不管了，可以执行其他的操作了。gpu就可以根据自己的顺序来执行这些命令。），那么就会有一个问题：cpu如何知道我的这些命令（或者是哪写命令）被执行了? 这就引出了围栏的概念。Fence就是一个同步对象，用来同步gpu线程和cpu线程。

主要实现原理就是，为gpu线程设置一个初始的围栏值，接着为这个值在设置一个cpu事件句柄，然后gpu继续执行任务，而cpu就等待，等到gpu达到这个围栏值的时候，，就唤醒事件，cpu就知道gpu的工作已经做完了，改cpu执行操作了。

## 资源屏障 resource barrier（gpu线程间的同步）

在渲染流程的中，我们可能对某个资源先读后写，比如DepthStencilBuffer，但是当gpu还没有对资源写完，就读取的化，就会造成**资源冒险**，有可能引发问题。所以就有了ResourceBarrier，告诉gpu当前资源是正在处于资源转换状态，从状态1 transition to 状态2。

## 超级采样SSAA 多重采样MSAA

超级采样：我们在确定屏幕上每一个像素的颜色的时候，将像素等分成4份子像素，然后分别确定每个子像素的颜色，然后在取4个子像素颜色的平均值当作像素颜色，这样做的化就会计算4次颜色，并且后台缓冲区以及深度缓冲区就会变成原来的4倍，加大了计算力度。

多重采样：我们在确定屏幕上每一个像素的颜色的时候，同样的也将像素分成4份子像素，与SSAA不同的是，我们首先获取像素中心位置的颜色ColorCenter，然后将ColorCenter赋值给4个子像素，接下来判断像素的可见性（通过深度模板测试），然后取4个子像素颜色的平均值，这样做的化就会计算1次颜色，大大减少了计算力度。

## 交换链

一种数据结构，它模拟了双缓冲的设计模式，，，在渲染过程中有两个缓冲区（前台缓冲区和后台缓冲区），我们在显示前台缓冲区所展示的内容的时候，会同时往后台缓冲区写入下一帧的数据，在后台缓冲区完成后会将前台后台交换，这样无缝切换减少画面闪烁的情况。

## 资源描述符

resource：在渲染出一幅画面的过程中所需要的各种数据（前台缓冲区、后台缓冲区、各种贴图、深度模板缓冲区等）

resource descriptor：这些资源对gpu来说只是一堆数据，gpu无法分辨出这些资源的类型、用途、大小、格式等信息，所以就有了资源描述符，用来描述每个资源的信息，使得gpu知道这些这些管线中的资源怎么处理

descriptor heap：用来存储同一种资源描述符资源描述符，可以看成资源描述符数组

## rootsignature

rootsignature就和cpp中的函数声明类似，是一种约定的行为（cpu与gpu之间的约定如何解释内存中的二进制数据）。

gpu再渲染的过程中，肯定需要各种各样的数据（纹理贴图，变换矩阵，法线，采样器信息等），而这些数据全是由cpu处理加载的，所以就需要有这么一种数据结构，用来描述这些数据。

也就是可以把gpu渲染看成是gpu调用的一个大函数，这些数据就是cpu向函数传递的参数。所以再执行这个函数之前，cpu必须和gpu之间约定好这些参数的类型，放在哪个寄存器中，参数的结构是怎样，这些就是rootsignature的作用。

> 需要注意的是rootsignature也需要序列化一下才能被gpu理解，也就是再创建rootsignture之前必须序列化。
>
> rootsignature中也可以直接设置rootdescriptor以及静态采样器，这些被认为是静态的，也就是每一个rootsignature绑定一个，如果需要改变就需要设置rootsignature。













# 2 渲染流水线

1 图元装配阶段：需要将传递进来的顶点数据，索引数据装配成一个个的三角形图元

2 顶点着色器阶段：

​	（model transformation）将局部空间的每个顶点，经过线性变换和平移变换到世界空间的位置上

​	（view transformation）将世界空间的坐标点变换到摄像机空间，，，摄像机变换矩阵：**3d中变换顺序为缩放->旋转->平移**，，，所以矩阵

[平移矩阵] * [旋转矩阵] * [坐标点]，，，但是view transformation是基变换，，所以需要求逆，，变成了[旋转矩阵]-1 * [平移矩阵]-1 * [坐标点]，

其中旋转矩阵是正交矩阵，逆就是转置，平移矩阵的逆就加个负号。

​	（projection transformation）投影变换

​				（orth projection）正交投影，将一个**视矩体转变换到一个中心点在原点的正方体**，此处依然**不采用3d中的变换顺序**，因为视矩体要变成正方体的缩放轴是以正方体原点为中心的，所以需要先将视矩体平移到摄像机空间下的原点，然后在进行缩放操作，也就是

[缩放矩阵] * [平移矩阵] * [坐标点]，无论是缩放还是平移都需要获取到视矩体的各项参数（near plane, far plane, top plane, bottom plane, left plane, right plane）,这些参数主要是通过（near plane, far plane, fov, width/height）求得。

平移就是将视矩体的中心点平移到原点，而缩放就是将位于原点的视矩体的[x,y,z轴]都缩放为2个单位长度。

​				（pers projection）透视投影，模拟实际情况，近大远小的效果，同样的将**视锥体变换到一个中心点在原点的正方体**，此处的方案**首先将视锥体变换成视矩体，在左乘正交投影矩阵**。此出所需要的参数是（ near plane, far plane），此出需要注意的是矩阵的第三行求法，用远近平面的z值，做特殊值代入法。

在左乘投影矩阵后，此时顶点会位于正方体中，也就是齐次剪裁空间，在这里我们可以保存每个点的w分量（表示每个点在世界空间下的深度值），然后在进行透视除法。

> 对平移矩阵的理解：我们所说的线性变换都是基于原点不变的情况，所以平移不是线性变换，他需要移动原点（这也是三维世界中变换顺序为缩放->旋转->平移的原因）。所以我们就用更高维度的矩阵来表示，拿二维点的平移举例，平移矩阵所构成的列空间是三维的，其中ox,oy都是标准正交基，而oz轴是假设为（dx,dy,1），我们在左乘平移矩阵后，就是将二维点的z分量也就是z方向上的单位向量，变换到列空间中oz轴上的单位向量，左乘完成后，在三维空间中的点，在xoy面上的投影点就是平移后点的位置。

> 对透视除法的理解：我们的投影操作是指把视锥体转换成位于原点的立方体，没有经过维度的变换，所以**投影矩阵应该是满秩的**，投影的过程中包括平移，所以**投影矩阵应该是四维的**，顶点在左乘投影矩阵后，会变换到四维空间中，四维空间中的w分量，决定了三维模型的放大和缩小，所以w应该一直保持为1，即透视除法。（可以类比三维空间中的投影仪，投影仪在墙上投影出一幅2d画面，在三维空间中w分量表示，投影仪与墙的距离，w增大->投影仪与墙的距离增大->2d画面越大，反之同理，所以三维空间中w分量控制了2d画面的放大和缩小，推导回四维空间中就可理解）。

3 曲面细分阶段：能够将网格中的三角形再细分成很多三角形，从而有高模，低模之分，即lod的实现。

4 几何着色器阶段：

5 剪裁：我们是在正方体空间做剪裁。在左乘透视投影之后透视除法之前执行剪裁，用遍历六个面对三角形进行剪裁（这里就有两种情况：剪裁出的是四边形或者是三角形）。

6 光栅化阶段：

​	视口变换，将经历剪裁后的顶点数据左乘视口变换矩阵（先缩放->平移）

​	背面剪裁，通过每个三角形的卷绕方向，通过三角形的法向量是否大于0，来决定此三角形是正向还是反向。

​	重心坐标插值来给每个像素上颜色：通过重心坐标来插值计算出三角形中人一顶点的各种数据（颜色，贴图位置）。

7 输出合并阶段，

# 3 材质模型

光照方向 lightDirection

顶点法线 Normal

环境光 AmbientLight

## 兰伯特材质

Pixel.color = material.BaseColor * dot(lightDirection, Normal) + material.BaseColor * AmbientLight

材质颜色 * （光线, 法向）夹角 + 材质颜色 * 环境光

也可以选择乘上光照强度

## 半兰伯特材质

Pixel.color = material.BaseColor * (dot(lightDirection, Normal) * 0.5 + 0.5) + material.BaseColor * AmbientLight

夹角余弦的取值为[-1， 1]，，这会导致一半的颜色取0，为黑色

[-1, 1] * 0.5 + 0.5 , 让整个颜色从[0, 1]

